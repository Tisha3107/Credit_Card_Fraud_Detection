{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58954e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "import streamlit as st\n",
    "import time\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0a21aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "def load_data():\n",
    "    try:\n",
    "        # Attempt to load from file if available\n",
    "        df = pd.read_csv('creditcard.csv')\n",
    "    except:\n",
    "        # If file not available, notify user\n",
    "        st.error(\"Please upload the creditcard.csv file to continue\")\n",
    "        df = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13038b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "def preprocess_data(df):\n",
    "    # Check for missing values\n",
    "    print(\"Missing values in each column:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    # Check the distribution of the 'Class' variable\n",
    "    print(\"\\nClass distribution:\")\n",
    "    print(df['Class'].value_counts())\n",
    "    \n",
    "    # Separate features from target\n",
    "    X = df.drop(['Class', 'Amount', 'Time'], axis=1)\n",
    "    \n",
    "    # Scale the Amount feature\n",
    "    amount = df['Amount'].values.reshape(-1, 1)\n",
    "    scaler = StandardScaler()\n",
    "    df['Amount_scaled'] = scaler.fit_transform(amount)\n",
    "    \n",
    "    # Scale the Time feature\n",
    "    time_feature = df['Time'].values.reshape(-1, 1)\n",
    "    df['Time_scaled'] = scaler.fit_transform(time_feature)\n",
    "    \n",
    "    # Prepare scaled dataset with all features\n",
    "    X_scaled = df.drop(['Class', 'Amount', 'Time'], axis=1)\n",
    "    X_scaled['Amount_scaled'] = df['Amount_scaled']\n",
    "    X_scaled['Time_scaled'] = df['Time_scaled']\n",
    "    \n",
    "    return X_scaled, df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89317ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality Reduction with PCA for Visualization\n",
    "def apply_pca(X_scaled):\n",
    "    pca = PCA(n_components=2)\n",
    "    principal_components = pca.fit_transform(X_scaled)\n",
    "    pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
    "    return pca_df, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6e3979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unsupervised Learning Models\n",
    "# 1 Isolation Forest\n",
    "def isolation_forest_model(X_scaled, contamination=0.01):\n",
    "    model = IsolationForest(contamination=contamination, random_state=42)\n",
    "    model.fit(X_scaled)\n",
    "    # Prediction: 1 for inliers, -1 for outliers\n",
    "    y_pred = model.predict(X_scaled)\n",
    "    # Convert to binary: 0 for inliers, 1 for outliers (frauds)\n",
    "    y_pred = [1 if pred == -1 else 0 for pred in y_pred]\n",
    "    return y_pred, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baaf8e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function to calculate feature importance for Isolation Forest\n",
    "def calculate_feature_importance(model, X):\n",
    "    # For each feature, we'll measure how much it contributes to anomaly detection\n",
    "    n_samples = X.shape[0]\n",
    "    n_features = X.shape[1]\n",
    "    \n",
    "    # Get the decision paths\n",
    "    # We'll use decision_function as a proxy for importance\n",
    "    anomaly_scores = -model.decision_function(X)  # Higher score = more anomalous\n",
    "    \n",
    "    # Calculate feature importance by correlation with anomaly scores\n",
    "    importance = np.zeros(n_features)\n",
    "    \n",
    "    for i in range(n_features):\n",
    "        # Calculate correlation between feature and anomaly score\n",
    "        corr = np.corrcoef(X.iloc[:, i], anomaly_scores)[0, 1]\n",
    "        importance[i] = np.abs(corr)  # Take absolute value of correlation\n",
    "    \n",
    "    # Normalize importance\n",
    "    if np.sum(importance) > 0:\n",
    "        importance = importance / np.sum(importance)\n",
    "        \n",
    "    return importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "413d20cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Local Outlier Factor\n",
    "def local_outlier_factor(X_scaled, contamination=0.01):\n",
    "    model = LocalOutlierFactor(n_neighbors=20, contamination=contamination)\n",
    "    # Prediction: 1 for inliers, -1 for outliers\n",
    "    y_pred = model.fit_predict(X_scaled)\n",
    "    # Convert to binary: 0 for inliers, 1 for outliers (frauds)\n",
    "    y_pred = [1 if pred == -1 else 0 for pred in y_pred]\n",
    "    return y_pred, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d1ac0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 DBSCAN\n",
    "def dbscan_model(X_scaled, eps=0.3, min_samples=10):\n",
    "    model = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    y_pred = model.fit_predict(X_scaled)\n",
    "    # In DBSCAN, -1 represents outliers\n",
    "    y_pred = [1 if pred == -1 else 0 for pred in y_pred]\n",
    "    return y_pred, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12235028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1': f1  # Key is 'F1', not 'F1 Score'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9ce4acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Functions\n",
    "def plot_pca_results(pca_df, y_true, y_pred=None):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    if y_pred is not None:\n",
    "        # Plot with predicted labels\n",
    "        plt.scatter(pca_df['PC1'], pca_df['PC2'], c=y_pred, cmap='coolwarm', alpha=0.7)\n",
    "        plt.title('PCA of Credit Card Transactions with Predicted Fraud')\n",
    "    else:\n",
    "        # Plot with actual labels\n",
    "        plt.scatter(pca_df['PC1'], pca_df['PC2'], c=y_true, cmap='coolwarm', alpha=0.7)\n",
    "        plt.title('PCA of Credit Card Transactions with Actual Fraud')\n",
    "    \n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.colorbar(label='Class')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a05da03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit Application\n",
    "def create_streamlit_app():\n",
    "    st.set_page_config(page_title=\"Credit Card Fraud Detection\", page_icon=\"ðŸ’³\", layout=\"wide\")\n",
    "    \n",
    "    st.title(\"Credit Card Fraud Detection \")\n",
    "    st.markdown(\"\"\"\n",
    "    This application uses unsupervised machine learning to detect fraudulent credit card transactions.\n",
    "    Upload your creditcard.csv file to get started.\n",
    "    \"\"\")\n",
    "    \n",
    "    # File uploader\n",
    "    uploaded_file = st.file_uploader(\"Upload creditcard.csv\", type=[\"csv\"])\n",
    "    \n",
    "    if uploaded_file is not None:\n",
    "        # Load data\n",
    "        df = pd.read_csv(uploaded_file)\n",
    "        st.success(\"File uploaded successfully!\")\n",
    "        \n",
    "        # Display raw data overview\n",
    "        with st.expander(\"View Raw Data Preview\"):\n",
    "            st.dataframe(df.head())\n",
    "            st.write(f\"Dataset Shape: {df.shape}\")\n",
    "        \n",
    "        # Data preprocessing\n",
    "        X_scaled, y_true = preprocess_data(df)\n",
    "        \n",
    "        # Show data statistics\n",
    "        with st.expander(\"Data Statistics\"):\n",
    "            st.write(\"Feature Statistics:\")\n",
    "            st.dataframe(X_scaled.describe())\n",
    "            \n",
    "            # Class distribution chart\n",
    "            fig = px.pie(names=['Normal', 'Fraud'], \n",
    "                         values=df['Class'].value_counts().values, \n",
    "                         title='Transaction Class Distribution')\n",
    "            st.plotly_chart(fig)\n",
    "        \n",
    "        # Apply PCA\n",
    "        pca_df, pca = apply_pca(X_scaled)\n",
    "        \n",
    "        # Model selection sidebar\n",
    "        st.sidebar.title(\"Model Configuration\")\n",
    "        model_choice = st.sidebar.selectbox(\n",
    "            \"Select Unsupervised Learning Model\",\n",
    "            [\"Isolation Forest\", \"Local Outlier Factor\", \"DBSCAN\"]\n",
    "        )\n",
    "        \n",
    "        # Model hyperparameters\n",
    "        if model_choice == \"Isolation Forest\":\n",
    "            contamination = st.sidebar.slider(\"Contamination\", 0.001, 0.1, 0.01, 0.001)\n",
    "            \n",
    "            with st.spinner('Training Isolation Forest model...'):\n",
    "                y_pred, model = isolation_forest_model(X_scaled, contamination)\n",
    "                \n",
    "        elif model_choice == \"Local Outlier Factor\":\n",
    "            contamination = st.sidebar.slider(\"Contamination\", 0.001, 0.1, 0.01, 0.001)\n",
    "            n_neighbors = st.sidebar.slider(\"Number of Neighbors\", 5, 50, 20)\n",
    "            \n",
    "            with st.spinner('Training Local Outlier Factor model...'):\n",
    "                model = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination)\n",
    "                y_pred = model.fit_predict(X_scaled.values)\n",
    "                y_pred = [1 if pred == -1 else 0 for pred in y_pred]\n",
    "                \n",
    "        elif model_choice == \"DBSCAN\":\n",
    "            eps = st.sidebar.slider(\"Epsilon\", 0.1, 5.0, 0.5, 0.1)\n",
    "            min_samples = st.sidebar.slider(\"Min Samples\", 5, 100, 10)\n",
    "            \n",
    "            with st.spinner('Training DBSCAN model...'):\n",
    "                y_pred, model = dbscan_model(X_scaled, eps, min_samples)\n",
    "        \n",
    "        # Model evaluation\n",
    "        results = evaluate_model(y_true, y_pred)\n",
    "        \n",
    "        # Display results\n",
    "        st.header(\"Model Results\")\n",
    "        \n",
    "        # Metrics - Fixed to use the correct keys\n",
    "        col1, col2, col3, col4 = st.columns(4)\n",
    "        col1.metric(\"Accuracy\", f\"{results['Accuracy']:.4f}\")\n",
    "        col2.metric(\"Precision\", f\"{results['Precision']:.4f}\")\n",
    "        col3.metric(\"Recall\", f\"{results['Recall']:.4f}\")\n",
    "        col4.metric(\"F1 Score\", f\"{results['F1']:.4f}\")  # Key is 'F1'\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        st.subheader(\"Confusion Matrix\")\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        fig = go.Figure(data=go.Heatmap(\n",
    "                z=cm,\n",
    "                x=['Predicted Normal', 'Predicted Fraud'],\n",
    "                y=['Actual Normal', 'Actual Fraud'],\n",
    "                hoverongaps=False,\n",
    "                colorscale='Viridis'))\n",
    "        \n",
    "        fig.update_layout(title=\"Confusion Matrix\")\n",
    "        st.plotly_chart(fig)\n",
    "        \n",
    "        # PCA Visualization\n",
    "        st.subheader(\"PCA Visualization\")\n",
    "        \n",
    "        # Create a dataframe with PCA components and class\n",
    "        pca_viz_df = pd.DataFrame({\n",
    "            'PC1': pca_df['PC1'],\n",
    "            'PC2': pca_df['PC2'],\n",
    "            'Actual Class': y_true,\n",
    "            'Predicted Class': y_pred\n",
    "        })\n",
    "        \n",
    "        # Create tabs for different visualizations\n",
    "        tab1, tab2 = st.tabs([\"Actual vs. Predicted\", \"Detailed View\"])\n",
    "        \n",
    "        with tab1:\n",
    "            col1, col2 = st.columns(2)\n",
    "            \n",
    "            with col1:\n",
    "                fig1 = px.scatter(pca_viz_df, x='PC1', y='PC2', color='Actual Class',\n",
    "                              title='PCA with Actual Fraud Labels',\n",
    "                              color_continuous_scale='Viridis')\n",
    "                st.plotly_chart(fig1)\n",
    "                \n",
    "            with col2:\n",
    "                fig2 = px.scatter(pca_viz_df, x='PC1', y='PC2', color='Predicted Class',\n",
    "                              title='PCA with Predicted Fraud Labels',\n",
    "                              color_continuous_scale='Viridis')\n",
    "                st.plotly_chart(fig2)\n",
    "        \n",
    "        with tab2:\n",
    "            # Interactive scatter plot\n",
    "            st.subheader(\"Interactive PCA Plot\")\n",
    "            fig = px.scatter(\n",
    "                pca_viz_df, x='PC1', y='PC2',\n",
    "                color='Predicted Class',\n",
    "                hover_data=['Actual Class'],\n",
    "                title='PCA of Credit Card Transactions',\n",
    "                color_continuous_scale='Viridis'\n",
    "            )\n",
    "            st.plotly_chart(fig)\n",
    "        \n",
    "        # Model-specific visualizations\n",
    "        st.header(f\"{model_choice} Analysis\")\n",
    "        \n",
    "        if model_choice == \"Isolation Forest\":\n",
    "            # Feature importance for Isolation Forest using our custom function\n",
    "            st.subheader(\"Feature Importance\")\n",
    "            \n",
    "            # Calculate feature importance using our custom function\n",
    "            try:\n",
    "                # Use our custom function to calculate feature importance\n",
    "                importances = calculate_feature_importance(model, X_scaled)\n",
    "                indices = np.argsort(importances)[::-1]\n",
    "                features = X_scaled.columns\n",
    "                \n",
    "                fig = go.Figure(go.Bar(\n",
    "                    x=[features[i] for i in indices],\n",
    "                    y=importances[indices],\n",
    "                    marker_color='green'\n",
    "                ))\n",
    "                fig.update_layout(title=\"Feature Importance in Isolation Forest\",\n",
    "                                 xaxis_title=\"Features\",\n",
    "                                 yaxis_title=\"Importance Score\")\n",
    "                st.plotly_chart(fig)\n",
    "                \n",
    "            except Exception as e:\n",
    "                st.warning(f\"Could not calculate feature importance. Details: {str(e)}\")\n",
    "                st.info(\"Showing feature distribution instead.\")\n",
    "                \n",
    "                # Show feature distributions as an alternative\n",
    "                fig = px.box(X_scaled, title=\"Feature Distributions\")\n",
    "                st.plotly_chart(fig)\n",
    "            \n",
    "        elif model_choice in [\"Local Outlier Factor\", \"DBSCAN\"]:\n",
    "            # Show anomaly scores distribution\n",
    "            st.subheader(\"Transaction Distribution\")\n",
    "            \n",
    "            # Create a figure with outliers highlighted\n",
    "            fig = px.scatter(\n",
    "                x=range(len(y_pred)),\n",
    "                y=X_scaled.iloc[:, 0],  # Using first feature as y-axis\n",
    "                color=[('Fraud' if p == 1 else 'Normal') for p in y_pred],\n",
    "                title=f\"Transactions with {model_choice} Outliers Highlighted\",\n",
    "                labels={\"x\": \"Transaction Index\", \"y\": \"Feature V1\"},\n",
    "                color_discrete_map={\"Normal\": \"blue\", \"Fraud\": \"red\"}\n",
    "            )\n",
    "            st.plotly_chart(fig)\n",
    "        \n",
    "        # Download predictions\n",
    "        prediction_df = pd.DataFrame({\n",
    "            'Actual': y_true,\n",
    "            'Predicted': y_pred\n",
    "        })\n",
    "        \n",
    "        st.download_button(\n",
    "            label=\"Download Predictions\",\n",
    "            data=prediction_df.to_csv(index=False),\n",
    "            file_name=\"fraud_predictions.csv\",\n",
    "            mime=\"text/csv\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ae12772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 13:27:22.048 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-30 13:27:22.051 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-30 13:27:23.383 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\Tisha Verma\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-03-30 13:27:23.384 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-30 13:27:23.384 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-30 13:27:23.385 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-30 13:27:23.385 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-30 13:27:23.386 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-30 13:27:23.386 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-30 13:27:23.386 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-30 13:27:23.387 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# Run the main Streamlit app\n",
    "if __name__ == \"__main__\":\n",
    "    create_streamlit_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ede05d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
