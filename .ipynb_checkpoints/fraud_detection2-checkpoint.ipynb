{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6308bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "import streamlit as st\n",
    "import time\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "691456fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Loading and Exploration\n",
    "# Load the dataset\n",
    "def load_data():\n",
    "    try:\n",
    "        # Attempt to load from file if available\n",
    "        df = pd.read_csv('creditcard.csv')\n",
    "    except:\n",
    "        # If file not available, notify user\n",
    "        st.error(\"Please upload the creditcard.csv file to continue\")\n",
    "        df = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bdd7ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Preprocessing\n",
    "def preprocess_data(df):\n",
    "    # Check for missing values\n",
    "    print(\"Missing values in each column:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    # Check the distribution of the 'Class' variable\n",
    "    print(\"\\nClass distribution:\")\n",
    "    print(df['Class'].value_counts())\n",
    "    \n",
    "    # Separate features from target\n",
    "    X = df.drop(['Class', 'Amount', 'Time'], axis=1)\n",
    "    \n",
    "    # Scale the Amount feature\n",
    "    amount = df['Amount'].values.reshape(-1, 1)\n",
    "    scaler = StandardScaler()\n",
    "    df['Amount_scaled'] = scaler.fit_transform(amount)\n",
    "    \n",
    "    # Scale the Time feature\n",
    "    time_feature = df['Time'].values.reshape(-1, 1)\n",
    "    df['Time_scaled'] = scaler.fit_transform(time_feature)\n",
    "    \n",
    "    # Prepare scaled dataset with all features\n",
    "    X_scaled = df.drop(['Class', 'Amount', 'Time'], axis=1)\n",
    "    X_scaled['Amount_scaled'] = df['Amount_scaled']\n",
    "    X_scaled['Time_scaled'] = df['Time_scaled']\n",
    "    \n",
    "    return X_scaled, df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27098b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Dimensionality Reduction with PCA for Visualization\n",
    "def apply_pca(X_scaled):\n",
    "    pca = PCA(n_components=2)\n",
    "    principal_components = pca.fit_transform(X_scaled)\n",
    "    pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
    "    return pca_df, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "062a650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Unsupervised Learning Models\n",
    "# 4.1 Isolation Forest\n",
    "def isolation_forest_model(X_scaled, contamination=0.01):\n",
    "    model = IsolationForest(contamination=contamination, random_state=42)\n",
    "    model.fit(X_scaled)\n",
    "    # Prediction: 1 for inliers, -1 for outliers\n",
    "    y_pred = model.predict(X_scaled)\n",
    "    # Convert to binary: 0 for inliers, 1 for outliers (frauds)\n",
    "    y_pred = [1 if pred == -1 else 0 for pred in y_pred]\n",
    "    return y_pred, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51ce741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Local Outlier Factor\n",
    "def local_outlier_factor(X_scaled, contamination=0.01):\n",
    "    model = LocalOutlierFactor(n_neighbors=20, contamination=contamination)\n",
    "    # Prediction: 1 for inliers, -1 for outliers\n",
    "    y_pred = model.fit_predict(X_scaled)\n",
    "    # Convert to binary: 0 for inliers, 1 for outliers (frauds)\n",
    "    y_pred = [1 if pred == -1 else 0 for pred in y_pred]\n",
    "    return y_pred, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffe646d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 DBSCAN\n",
    "def dbscan_model(X_scaled, eps=0.3, min_samples=10):\n",
    "    model = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    y_pred = model.fit_predict(X_scaled)\n",
    "    # In DBSCAN, -1 represents outliers\n",
    "    y_pred = [1 if pred == -1 else 0 for pred in y_pred]\n",
    "    return y_pred, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "434d7971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Model Evaluation\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return {\n",
    "        'Accuracy': accuracy*100,\n",
    "        'Precision': precision*100,\n",
    "        'Recall': recall*100,\n",
    "        'F1': f1  # Fixed: Changed 'F1 Score' to 'F1' to match the key being used\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b902322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Visualization Functions\n",
    "def plot_pca_results(pca_df, y_true, y_pred=None):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    if y_pred is not None:\n",
    "        # Plot with predicted labels\n",
    "        plt.scatter(pca_df['PC1'], pca_df['PC2'], c=y_pred, cmap='coolwarm', alpha=0.7)\n",
    "        plt.title('PCA of Credit Card Transactions with Predicted Fraud')\n",
    "    else:\n",
    "        # Plot with actual labels\n",
    "        plt.scatter(pca_df['PC1'], pca_df['PC2'], c=y_true, cmap='coolwarm', alpha=0.7)\n",
    "        plt.title('PCA of Credit Card Transactions with Actual Fraud')\n",
    "    \n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.colorbar(label='Class')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f465a9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(X_scaled, model_name, model=None):\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    if model_name == \"Isolation Forest\" and model is not None:\n",
    "        # For Isolation Forest we can extract feature importance\n",
    "        importances = model.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        features = X_scaled.columns\n",
    "        \n",
    "        plt.title('Feature Importances in Isolation Forest')\n",
    "        plt.bar(range(X_scaled.shape[1]), importances[indices], align='center')\n",
    "        plt.xticks(range(X_scaled.shape[1]), [features[i] for i in indices], rotation=90)\n",
    "        plt.xlabel('Features')\n",
    "        plt.ylabel('Importance')\n",
    "        plt.tight_layout()\n",
    "    else:\n",
    "        # For other models, show feature distributions\n",
    "        plt.title(f'Feature Distributions for {model_name}')\n",
    "        X_scaled.hist(figsize=(14, 10), bins=50)\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8859369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Streamlit Application\n",
    "def create_streamlit_app():\n",
    "    st.set_page_config(page_title=\"Credit Card Fraud Detection\", page_icon=\"ðŸ’³\", layout=\"wide\")\n",
    "    \n",
    "    st.title(\"Credit Card Fraud Detection - Unsupervised Machine Learning\")\n",
    "    st.markdown(\"\"\"\n",
    "    This application uses unsupervised machine learning to detect fraudulent credit card transactions.\n",
    "    Upload your creditcard.csv file to get started.\n",
    "    \"\"\")\n",
    "    \n",
    "    # File uploader\n",
    "    uploaded_file = st.file_uploader(\"Upload creditcard.csv\", type=[\"csv\"])\n",
    "    \n",
    "    if uploaded_file is not None:\n",
    "        # Load data\n",
    "        df = pd.read_csv(uploaded_file)\n",
    "        st.success(\"File uploaded successfully!\")\n",
    "        \n",
    "        # Display raw data overview\n",
    "        with st.expander(\"View Raw Data Preview\"):\n",
    "            st.dataframe(df.head())\n",
    "            st.write(f\"Dataset Shape: {df.shape}\")\n",
    "        \n",
    "        # Data preprocessing\n",
    "        X_scaled, y_true = preprocess_data(df)\n",
    "        \n",
    "        # Show data statistics\n",
    "        with st.expander(\"Data Statistics\"):\n",
    "            st.write(\"Feature Statistics:\")\n",
    "            st.dataframe(X_scaled.describe())\n",
    "            \n",
    "            # Class distribution chart\n",
    "            fig = px.pie(names=['Normal', 'Fraud'], \n",
    "                         values=df['Class'].value_counts().values, \n",
    "                         title='Transaction Class Distribution')\n",
    "            st.plotly_chart(fig)\n",
    "        \n",
    "        # Apply PCA\n",
    "        pca_df, pca = apply_pca(X_scaled)\n",
    "        \n",
    "        # Model selection sidebar\n",
    "        st.sidebar.title(\"Model Configuration\")\n",
    "        model_choice = st.sidebar.selectbox(\n",
    "            \"Select Unsupervised Learning Model\",\n",
    "            [\"Isolation Forest\", \"Local Outlier Factor\", \"DBSCAN\"]\n",
    "        )\n",
    "        \n",
    "        # Model hyperparameters\n",
    "        if model_choice == \"Isolation Forest\":\n",
    "            contamination = st.sidebar.slider(\"Contamination\", 0.001, 0.1, 0.01, 0.001)\n",
    "            \n",
    "            with st.spinner('Training Isolation Forest model...'):\n",
    "                y_pred, model = isolation_forest_model(X_scaled, contamination)\n",
    "                \n",
    "        elif model_choice == \"Local Outlier Factor\":\n",
    "            contamination = st.sidebar.slider(\"Contamination\", 0.001, 0.1, 0.01, 0.001)\n",
    "            n_neighbors = st.sidebar.slider(\"Number of Neighbors\", 5, 50, 20)\n",
    "            \n",
    "            with st.spinner('Training Local Outlier Factor model...'):\n",
    "                model = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination)\n",
    "                y_pred = model.fit_predict(X_scaled.values)\n",
    "                y_pred = [1 if pred == -1 else 0 for pred in y_pred]\n",
    "                \n",
    "        elif model_choice == \"DBSCAN\":\n",
    "            eps = st.sidebar.slider(\"Epsilon\", 0.1, 5.0, 0.5, 0.1)\n",
    "            min_samples = st.sidebar.slider(\"Min Samples\", 5, 100, 10)\n",
    "            \n",
    "            with st.spinner('Training DBSCAN model...'):\n",
    "                y_pred, model = dbscan_model(X_scaled, eps, min_samples)\n",
    "        \n",
    "        # Model evaluation\n",
    "        results = evaluate_model(y_true, y_pred)\n",
    "        \n",
    "        # Display results\n",
    "        st.header(\"Model Results\")\n",
    "        \n",
    "        # Metrics - Fixed the KeyError by making sure the keys match\n",
    "        col1, col2, col3, col4 = st.columns(4)\n",
    "        col1.metric(\"Accuracy\", f\"{results['Accuracy']:.4f}\")\n",
    "        col2.metric(\"Precision\", f\"{results['Precision']:.4f}\")\n",
    "        col3.metric(\"Recall\", f\"{results['Recall']:.4f}\")\n",
    "        col4.metric(\"F1 Score\", f\"{results['F1']:.4f}\")  # Key is 'F1', not 'F1 Score'\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        st.subheader(\"Confusion Matrix\")\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        fig = go.Figure(data=go.Heatmap(\n",
    "                z=cm,\n",
    "                x=['Predicted Normal', 'Predicted Fraud'],\n",
    "                y=['Actual Normal', 'Actual Fraud'],\n",
    "                hoverongaps=False,\n",
    "                colorscale='Viridis'))\n",
    "        \n",
    "        fig.update_layout(title=\"Confusion Matrix\")\n",
    "        st.plotly_chart(fig)\n",
    "        \n",
    "        # PCA Visualization\n",
    "        st.subheader(\"PCA Visualization\")\n",
    "        \n",
    "        # Create a dataframe with PCA components and class\n",
    "        pca_viz_df = pd.DataFrame({\n",
    "            'PC1': pca_df['PC1'],\n",
    "            'PC2': pca_df['PC2'],\n",
    "            'Actual Class': y_true,\n",
    "            'Predicted Class': y_pred\n",
    "        })\n",
    "        \n",
    "        # Create tabs for different visualizations\n",
    "        tab1, tab2 = st.tabs([\"Actual vs. Predicted\", \"Detailed View\"])\n",
    "        \n",
    "        with tab1:\n",
    "            col1, col2 = st.columns(2)\n",
    "            \n",
    "            with col1:\n",
    "                fig1 = px.scatter(pca_viz_df, x='PC1', y='PC2', color='Actual Class',\n",
    "                              title='PCA with Actual Fraud Labels',\n",
    "                              color_continuous_scale='Viridis')\n",
    "                st.plotly_chart(fig1)\n",
    "                \n",
    "            with col2:\n",
    "                fig2 = px.scatter(pca_viz_df, x='PC1', y='PC2', color='Predicted Class',\n",
    "                              title='PCA with Predicted Fraud Labels',\n",
    "                              color_continuous_scale='Viridis')\n",
    "                st.plotly_chart(fig2)\n",
    "        \n",
    "        with tab2:\n",
    "            # Interactive scatter plot\n",
    "            st.subheader(\"Interactive PCA Plot\")\n",
    "            fig = px.scatter(\n",
    "                pca_viz_df, x='PC1', y='PC2',\n",
    "                color='Predicted Class',\n",
    "                hover_data=['Actual Class'],\n",
    "                title='PCA of Credit Card Transactions',\n",
    "                color_continuous_scale='Viridis'\n",
    "            )\n",
    "            st.plotly_chart(fig)\n",
    "        \n",
    "        # Model-specific visualizations\n",
    "        st.header(f\"{model_choice} Analysis\")\n",
    "        \n",
    "        if model_choice == \"Isolation Forest\":\n",
    "            # Feature importance for Isolation Forest\n",
    "            st.subheader(\"Feature Importance\")\n",
    "            importances = model.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]\n",
    "            features = X_scaled.columns\n",
    "            \n",
    "            fig = go.Figure(go.Bar(\n",
    "                x=[features[i] for i in indices],\n",
    "                y=importances[indices],\n",
    "                marker_color='green'\n",
    "            ))\n",
    "            fig.update_layout(title=\"Feature Importance in Isolation Forest\",\n",
    "                             xaxis_title=\"Features\",\n",
    "                             yaxis_title=\"Importance Score\")\n",
    "            st.plotly_chart(fig)\n",
    "            \n",
    "        elif model_choice in [\"Local Outlier Factor\", \"DBSCAN\"]:\n",
    "            # Show anomaly scores distribution\n",
    "            st.subheader(\"Transaction Distribution\")\n",
    "            \n",
    "            # Create a figure with outliers highlighted\n",
    "            fig = px.scatter(\n",
    "                x=range(len(y_pred)),\n",
    "                y=X_scaled.iloc[:, 0],  # Using first feature as y-axis\n",
    "                color=[('Fraud' if p == 1 else 'Normal') for p in y_pred],\n",
    "                title=f\"Transactions with {model_choice} Outliers Highlighted\",\n",
    "                labels={\"x\": \"Transaction Index\", \"y\": \"Feature V1\"},\n",
    "                color_discrete_map={\"Normal\": \"blue\", \"Fraud\": \"red\"}\n",
    "            )\n",
    "            st.plotly_chart(fig)\n",
    "        \n",
    "        # Download predictions\n",
    "        prediction_df = pd.DataFrame({\n",
    "            'Actual': y_true,\n",
    "            'Predicted': y_pred\n",
    "        })\n",
    "        \n",
    "        st.download_button(\n",
    "            label=\"Download Predictions\",\n",
    "            data=prediction_df.to_csv(index=False),\n",
    "            file_name=\"fraud_predictions.csv\",\n",
    "            mime=\"text/csv\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e0397f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 13:14:45.338 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-30 13:14:45.343 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-30 13:14:47.242 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\Tisha Verma\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-03-30 13:14:47.244 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-30 13:14:47.245 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-30 13:14:47.246 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-30 13:14:47.247 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-30 13:14:47.250 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-30 13:14:47.252 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-30 13:14:47.253 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-30 13:14:47.255 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# Run the main Streamlit app\n",
    "if __name__ == \"__main__\":\n",
    "    create_streamlit_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52751c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
